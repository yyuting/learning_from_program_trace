
import sys
import copy
import numpy
import string
import pprint
import hashlib
import subprocess
import os, os.path
sys.path += ['../solver']
import util
import traceback
import math
import functools
import time
import inspect
import random
import shutil
import glob
import multiprocessing
import atexit
import filelock

sys.setrecursionlimit(10**6)

builtin_min = min
builtin_max = max

assert sys.version_info[0] == 3, 'requires Python 3'

int_types = (int, numpy.int8, numpy.int16, numpy.int32, numpy.int64)
float_types = (float, numpy.float32, numpy.float64)


DEFAULT_ARGUMENT_ARRAY_NAME = 'X'
VECTOR_TYPE = 'VectorXd'
MATRIX_TYPE = 'MatrixXd'
DEFAULT_ARGUMENT_ARRAY_DTYPE = VECTOR_TYPE + ' &'
DEFAULT_CLASS_NAME = 'CompilerProblem'
DEFAULT_ARGUMENT_GRAD = 'grad'
OUTPUT_ARRAY = 'vec_output'                 # Additional vector output
COMPILER_PROBLEM_PY = 'compiler_problem.py'

SOURCE_PY_FILE_BEGIN = """
# A problem automatically generated by our compiler infrastructure.
# Only include this header from one source file.

import sys; sys.path += ['..']
from tf_util import *
"""


# Different modes for to_source()
MODE_VARNAME = 'varname'                # Generate variable name for use in expression
MODE_INLINE = 'inline'                  # Usually generate inlined expression code (do not generate temporary variable names)
MODE_ALWAYS_INLINE = 'always_inline'    # Always inline (never generate references to existing vars or empty strings)
MODE_SAMPLE_PROBLEM = 'sample_problem'  # Generate fused/inlined initialization code in sample_problem() method
MODE_SIDE_EFFECTS = 'side_effects'      # Generate ordinary statements with side effects (e.g. for loops)


no_generate_duplicates = True                           # Do not generate duplicate code

# * Can transform a whole sub-graph of the AST (has non-local effects), e.g. APPROX_MC generates passes n samples through the sub-graph

compile_lock = None
print_benchmark = True                                  # Print some time benchmarks

log_intermediates_less = False                           # log less features

has_non_raymarching_loop = False                        # Whether there is a non raymarching loop (that needs to try for subsampling count in automatic mode)

INT_TYPE = 'int'
REAL_TYPE = 'double'
VOID_TYPE = 'void'
STR_TYPE = 'str'


DERIV_PREFIX = 'dans_d'                                 # Prefix before derivative variables

log_prefix = '_log_'
log_prefix_only = True

log_intermediates_rank = 0
log_intermediates_subset_rank = 0       # workaround so that auxiliary features can reuse all features scale and bias

DEFAULT_FOR_LOOP_NAME = None
DEFAULT_FOR_LOOP_ITER = None
DEFAULT_COND_FUNC = None
DEFAULT_IS_LOOP_COND = False

__loop_cond = {}

DEFAULT_DO_LOG = True

loop_varname_seperator = '__sep__'
loop_name_prefix = '__loop'
raymarching_loop_name_prefix = '__raymarching'
loop_name_count = 0
global_for_loop_dict = {}
global_for_loop_id = {}

def_name_prefix = '__def__'

last_for_loop_name = None

def_func_names = {}


def add_loop_cond(*args):
    
    global __loop_cond
    
    if DEFAULT_COND_FUNC is None:
        return
    if DEFAULT_FOR_LOOP_NAME not in __loop_cond:
        __loop_cond[DEFAULT_FOR_LOOP_NAME] = {}
    if DEFAULT_FOR_LOOP_ITER in __loop_cond[DEFAULT_FOR_LOOP_NAME]:
        raise
    global DEFAULT_IS_LOOP_COND
    DEFAULT_IS_LOOP_COND = True
    cond = DEFAULT_COND_FUNC(*args)
    __loop_cond[DEFAULT_FOR_LOOP_NAME][DEFAULT_FOR_LOOP_ITER] = cond
    DEFAULT_IS_LOOP_COND = False

def simplify_clean_up_loop_dict(new_node, old_node, clean_list, do_log=None):
    new_node.for_loop_name = old_node.for_loop_name
    new_node.for_loop_iter = old_node.for_loop_iter
    new_node.loop_specified_name = old_node.loop_specified_name
    
    new_node.log_intermediates_subset_rank = numpy.max([new_node.log_intermediates_subset_rank, old_node.log_intermediates_subset_rank] + [node.log_intermediates_subset_rank for node in clean_list])
        
    if do_log is not None:
        new_node.do_log = do_log
    else:
        new_node.do_log = old_node.do_log
    if new_node.for_loop_name is not None and new_node.for_loop_iter is not None:
        global global_for_loop_id
        global global_for_loop_dict
        try:
            replace_idx = global_for_loop_id[new_node.for_loop_name][new_node.for_loop_iter].index(id(old_node))
            if new_node.for_loop_name == '__loop0' and new_node.for_loop_iter == 0 and replace_idx == 22:
                replace_idx = 22
        except:
            raise
        global_for_loop_dict[new_node.for_loop_name][new_node.for_loop_iter][replace_idx] = new_node
        global_for_loop_id[new_node.for_loop_name][new_node.for_loop_iter][replace_idx] = id(new_node)
        for node in clean_list:
            if hasattr(node, 'parents'):
                delattr(node, 'parents')
            node.garbage_collected = True



class CompilerParams:
    def __init__(self, **kw):
        self.var_list = []                  # Variables indexed by evaluation order
        self.named_var_list = []            # Variables given a name by defined as Var
        self.logged_var_list = []           # Variables that will be logged to full program trace (excluding loop variables in middle iterations if collecting loop statistic)
        self.var_type = []                  # Variable type by evaluation order.
        self.instance_dtype = {}            # Maps instance var name to dtype if instance var.
        self.name_to_order = {}             # Map variable name to evaluation order.
        self.loop_vars_seen = set()         # Set of LoopVar variable names for which we have generated source code.
        self.log_intermediates_list = []    # Set of variables whose log_intermediates_rank is higher or equal to log_intermediates_level
        self.log_intermediates_subset_list = [] # Set of variables whose log_intermediates_subset_rank is higher or equal to log_intermediates_subset_level, workaround so that auxiliary features can reuse scale and bias from all features

        self.root = True                    # Processing root node in expression?
        self.mode = MODE_VARNAME            # One of MODE_*.
        self.recurse = True                 # Whether to include child node source code when Expr.to_source() is called.
        self.cache_to_source = {}           # Maps original Expr id to source
        self.save_method = ''               # Save method declaration (if any)
        self.global_header = []             # List of strings for classes and global variables
        self.log_rho = False                # Log list of correlation coefficients rho
        self.log_rho_count = 0              # Number of correlation coefficients logged
        self.statement_ids = set()          # Ids of nodes that correspond to generated statements (to prevent duplicating statements)
        self.generated_nodes = []
        self.constructor_code = []          # List of custom code strings to go at end of constructor
        self.tf_global_code = []            # List of custom code strings to go to the global dlmain of the tensorflow file
        self.trace = False                  # Print values of variables using printfs
        self.log_intermediates = False      # Log intermediate values
        self.intermediate_funcs = 'fg'      # Functions to log intermediates for
        self.samples = 1                    # Samples of f and g evaluated at compile time (useful for learning from multiple samples)
        self.rng_counter = {}               # Random number generator counter
        self.msaa_samples = 1
        self.is_Var = False                 # is current Expr a Var?
        self.log_intermediates_level = 0    # from which level do we start log intermedate variables?
        self.log_intermediates_subset_level = 1 # workaround for auxiliary features
        self.for_loop_dict = {}             # Collect for loop information
        self.collect_loop_statistic = False # A flag indicating whether we're collecting loop statistics at the current run
        self.first_last_only = False        # A flag indicating which loop statistic to collect, if False, collect first, last, mean and std, if True, collect only first and last
        self.last_only = False              # A flag indicating whether to collect only last of iterations
        self.subsample_loops = None         # If set as int n, log every nth iteration
        self.last_n = None                  # If set as int n, log the last n iterations
        self.first_n = None                 # If set as int n, log the first n iterations plus the last iteration
        self.first_n_no_last = None         # If set as int n, log the first n iterations
        self.mean_var_only = False          # If flagged, collect only mean and variance
        self.automate_loop_statistic = False # If flagged, automatically choose loop subsampling strategy
        self.def_loop_log_last = False      # If false, log first, else, log last
        self.log_only_return_def_raymarching = False # If true and if in automate_loop_statistic mode, log only the return value of def and raymarching loop
        self.simplify_compute_graph = True  # A flag indicating whether we wanna simplify the compute graph, set to False only for debugging purposes
        self.const_vars = []                # A list containing variable names that may be a constant scale or bias to other variables

        self.every_nth = None               # If not None, every nth variable in traversal order
        self.every_nth_stratified = False   # If True, randomly sample a trace from every nth trace
        self.stratified_random_file = None  # If specified, use offset in this file to generate stratified samples, instead of randomly generate them on the fly
        self.one_hop_parent = False         # If true, only log a varabiel if any of its parent is not logged
        self.chron_order = False            # If false, log_list will use default depth first traversal starting from the output node; if true, log_list will follow a chronological order of the program execution: features computed first will have smaller index in the list
        
        self.orig_dir_name = None
        
        self.log_getitem = True             # If false, do not log trace for argument array getitem
        
        self.robust_simplification = False  # If true, robustly simplify the compute graph, regardless whether collect_lop_statistic is required (default to False to allow legacy compiler result to be consistent)
        
        self.loop_log_scope = {}            # Specifies the logging scope where the loop resides, e.g. if loop is used only by variables / outer loop whose do_log = False, the entire inner loop shouldn't be logged

        for (key, value) in kw.items():
            if hasattr(self, key):
                setattr(self, key, value)
            else:
                raise ValueError('unknown key for CompilerParams: %s (no corresponding attribute)'%key)

    def reset_vars(self):
        self.var_list = []
        self.name_to_order = {}
        self.named_var_list = []
        self.logged_var_list = []

    def reset(self):
        self.loop_vars_seen = set()
        self.statement_ids = set()
        self.generated_nodes = []
        self.rng_counter = {}

    def as_reset_statements(self):
        ans = copy.copy(self)
        ans.statement_ids = set()
        return ans


    def __repr__(self):
        return 'CompilerParams(%s)]'%(', '.join('%s=%r'%(key, getattr(self, key)) for key in sorted(self.__dict__.keys())))

    def deroot(self):
        """
        A copy of self that has root set to False (not processing root node in expression).
        """
        ans = copy.copy(self)
        ans.root = False
        return ans

    def as_mode(self, mode):
        """
        A copy of self that has mode set to the given target.
        """
        ans = copy.copy(self)
        ans.mode = mode
        return ans


    def get_varname(self, short_name, full_name, dtype, is_instance=False, rank=0, subset_rank=0, loop_specified_name=None, do_log=True):
        """
        Convert a variable or expression name into a variable numbered by evaluation order.

        Here short_name is a descriptive identifier string that will be used in the variable, and
        full_name is a full unique identifier string.

        Return the converted variable name.
        """
        if is_instance:
            self.instance_dtype[full_name] = dtype
            return full_name
        if full_name in self.name_to_order:
            return self.var_list[self.name_to_order[full_name]]
        n = len(self.var_list)
        self.name_to_order[full_name] = n
        allowed_chars = set(string.ascii_letters + string.digits)
        try:
            remain = '_' + ''.join([c if c in allowed_chars else '_' for c in short_name])
        except:
            # debug purpose
            raise
        if remain == '_':
            remain = ''
        if False:
        #if for_loop_name is not None and for_loop_iter is not None:
            if for_loop_name not in self.for_loop_dict:
                self.for_loop_dict[for_loop_name] = {}
            if for_loop_iter not in self.for_loop_dict[for_loop_name]:
                self.for_loop_dict[for_loop_name][for_loop_iter] = []
            n = len(self.for_loop_dict[for_loop_name][for_loop_iter])
            converted_name = 'loopvar_' + for_loop_name + '_' + str(for_loop_iter) + loop_varname_seperator + 'var%03d'%n
            self.for_loop_dict[for_loop_name][for_loop_iter].append(converted_name)
        if loop_specified_name is not None:
            #if self.chron_order:
            if True:
                converted_name = 'var%05d'%n + loop_specified_name
            else:
                converted_name = loop_specified_name
        else:
            converted_name = 'var%05d'%n + remain

        if do_log:
            self.logged_var_list.append(converted_name)

        if self.is_Var:
            if log_prefix_only:
                if short_name.startswith(log_prefix):
                    self.named_var_list.append(converted_name)
            else:
                self.named_var_list.append(converted_name)

        self.var_list.append(converted_name)
        self.var_type.append(dtype)
        if rank >= self.log_intermediates_level:
            self.log_intermediates_list.append(converted_name)
        if subset_rank >= self.log_intermediates_subset_level:
            self.log_intermediates_subset_list.append(converted_name)
#        print('get_varname', converted_name)
        return converted_name



    def var_declarations(self, is_instance=False):
        if is_instance:
            return '\n'.join(dtype + ' ' + name + ';' for (name, dtype) in self.instance_dtype.items())
        else:
            return '\n'.join(self.var_type[i] + ' ' + self.var_list[i] + ';' for i in range(len(self.var_list)))


def simplify(e):
    """
    Return a copy of the given Expr that is simplified.
    """
    e = copy.deepcopy(e)
    return e.simplify()

def reverse_lines(s):
    return '\n'.join(s.split('\n')[::-1])

def eliminate_duplicates(s):

    L = s.split('\n')
    ans = []
    ans_set = set()
    for x in L:
        xs = x.strip()
        if not '{' in xs and not '}' in xs and not xs.startswith('//'):
            if xs not in ans_set:
                ans.append(x)
                ans_set.add(xs)
        else:
            ans.append(x)
    ans_s = '\n'.join(ans)
    
    return ans_s



def system(cmd):

    try:
        cmd_output = subprocess.check_output(cmd, stderr=subprocess.STDOUT, shell=True, universal_newlines=True)
    except subprocess.CalledProcessError as exc:
        print(exc.output)
        raise ValueError("Subprocess failed with code ", exc.returncode)
    else:
        return cmd_output

class ParseError(Exception):
    pass


class CheckFailed(Exception):
    pass


def check(e, compiler_params, cmd=None, time_error=False, nerror=-1, nground=-1, nsamples=0, precompute_samples=None, print_command=False, log_rho=False, do_copy=True, extra_args='', do_run=True, do_compile=True, get_command=False, skip_save=False, ndims=-1, our_id=None, sanity_code=None, code_only=False):
    """
    Convert Expr to finalized source code and (by default) run to check the correctness or performance of the output code.

    If time_error is True then return time and error information in a dict. Here nerror and nground control the
    number of samples to estimate the error and estimate the ground truth by convolution (if -1, use default).

    If log_rho is True then return log_rho as a key in a dict containing correlation coefficients.

    If precompute_samples is an integer then set the #define PRECOMPUTE_SAMPLES to the given integer in problems.cpp.

    If do_compile is True then generate and compile C++ code. If do_run is True then run the target program (unless get_command is True, in which
    case, do not run but instead return the command to run (with full path-name included)."
    """
    ans = {}

    csolver_path = '../apps'
    if our_id is None:
        our_id = util.machine_process_id()
    h_filename = our_id + COMPILER_PROBLEM_PY
    orig_h_filename = 'compiler_problem_orig.py'
    
    
    if ndims <= 0:
        try:
            arg_array = locate_argument_array(e)
            arg_array_ndims = arg_array.ndims
        except NoArgumentArray:
            arg_array_ndims = 1
    if cmd is None:
        check_g_int = 3
        if nsamples != 0:
            check_g_int = 0

        check_command_begin = 'python tf_parser.py '
        check_command = check_command_begin +  '--ndims %d --check_g %d --samples %d' % (ndims if ndims > 0 else arg_array_ndims, check_g_int, nsamples)
    else:
        check_command = cmd
    if time_error:
        check_command += ' --error %d --ground %d' % (nerror, nground)
    if log_rho:
        check_command += ' --print_rho 1'
    if len(extra_args):
        check_command += ' ' + extra_args
    if skip_save:
        check_command += ' --skip_save 1'
    
    check_command += ' --our_id %s' % our_id

    if do_compile:
        T0 = time.time()
        
        source = to_source(e, compiler_params, info_d=ans, do_copy=do_copy, sanity_code=sanity_code)
        
        T1 = time.time()
        h_filename_full = os.path.join(csolver_path, h_filename)
        current_source = ''
        if os.path.exists(h_filename_full):
            with open(h_filename_full, 'rt') as f:
                current_source = f.read()
        if current_source != source:
            with open(h_filename_full, 'wt') as f:
                f.write(source)
            shutil.copyfile(h_filename_full, orig_h_filename)
        if print_benchmark:
            print('Generated C++ code in %f seconds' % (T1-T0))

    old_path = os.getcwd()
    os.chdir(csolver_path)

    

    if print_command and do_run:
        print(check_command)

    if get_command:
        ans = check_command
        do_run = False

    if do_run:
        T0 = time.time()
        check_out = subprocess.check_output(check_command, shell=True)
        T1 = time.time()
        check_out = check_out.decode('utf-8')
        

    os.chdir(old_path)
    if get_command:
        return ans
    
    return ans

def print_header(s, file=None):
    if file is None:
        file = sys.stdout
    print('-'*80, file=file)
    print(s, file=file)
    print('-'*80, file=file)

class NoArgumentArray(Exception):
    pass

def is_unknown_array(node):
    """
    Returns whether the given Expr is an ArgumentArray for the unknown array argument of the solver.
    """
    return isinstance(node, ArgumentArray) and node.name == DEFAULT_ARGUMENT_ARRAY_NAME

def locate_argument_array(e):
    """
    Return ArgumentArray instance for unknown array given objective function Expr, or raise exception if not found.
    """
    for node in e.all_nodes():
        if is_unknown_array(node):
            return node
    raise NoArgumentArray

def to_source_nonfinal(e, compiler_params, eliminate=True, can_log_intermediates=False, is_f=False):
    """
    Convert Expr to non-finalized source code (no wrapping class).
    """
    s = e.to_source(compiler_params)
    
    if compiler_params.chron_order:
        pass
    
    
    if eliminate:
        s = eliminate_duplicates(s)
    
    if can_log_intermediates and compiler_params.log_intermediates:
        log_s = ''
        var_count = 0
        fgname = 'f' if is_f else 'g'

        if compiler_params.log_intermediates_level > 0:
            log_list = sorted(compiler_params.log_intermediates_list)
        else:
            log_list = sorted(compiler_params.named_var_list) if log_intermediates_less else sorted(compiler_params.logged_var_list)

        if compiler_params.every_nth is not None:
            if not compiler_params.every_nth_stratified:
                log_list = [log_list[i] for i in range(len(log_list)) if (i % compiler_params.every_nth == 0)]
            else:
                log_list_len = int(numpy.ceil(len(log_list) / compiler_params.every_nth))
                stratified_log_list = []
                if compiler_params.stratified_random_file is not None:
                    stratified_random_offset = numpy.load(compiler_params.stratified_random_file)
                    assert stratified_random_offset.shape[0] == log_list_len
                else:
                    stratified_random_offset = -numpy.ones(log_list_len, dtype='i')
                for i in range(log_list_len):
                    ind_low = i * compiler_params.every_nth
                    ind_hi = (i + 1) * compiler_params.every_nth
                    if ind_hi > len(log_list):
                        ind_hi = len(log_list)
                    if stratified_random_offset[i] != -1:
                        assert stratified_random_offset[i] >= 0
                        assert stratified_random_offset[i] + ind_low < ind_hi
                        chosen_ind = stratified_random_offset[i] + ind_low
                    else:
                        chosen_ind = numpy.random.randint(ind_low, ind_hi)
                        stratified_random_offset[i] = chosen_ind - ind_low
                    stratified_log_list.append(log_list[chosen_ind])
                log_list = stratified_log_list
                if compiler_params.stratified_random_file is None:
                    numpy.save('stratified_random_file.npy', stratified_random_offset)

        if compiler_params.log_intermediates_subset_level > 0:
            log_subset_list = sorted(compiler_params.log_intermediates_subset_list)
        else:
            log_subset_list = []

        for var_name in log_list:
            if (not var_name.startswith(DERIV_PREFIX)) and (not var_name.startswith('loopvar')):
                log_s += '%s_log_intermediate[%d] = %s' %(fgname, var_count, var_name)

                log_s += '\n'
                var_count += 1

        if False:
            for key, val in compiler_params.for_loop_dict.items():
                iters = list(val.keys())
                niters = numpy.max(iters)
                if 0 in iters:
                    log_list = val[niters] + val[0]
                else:
                    log_list = val[niters]
                for var_name in log_list:
                    log_s += '%s_log_intermediate[%d] = %s' %(fgname, var_count, var_name)

                    log_s += '\n'
                    var_count += 1
                nvars_per_loop = len(val[niters])
                other_iters = list(range(1, niters))
                var_id_lookup = {}
                for iter in other_iters:
                    assert iter in iters
                    assert len(val[iter]) == nvars_per_loop
                    for var_name in val[iter]:
                        idx = var_name.index(loop_varname_seperator) + len(loop_varname_seperator)
                        short_var_name = var_name[idx:]
                        if short_var_name not in var_id_lookup.keys():
                            log_s += '%s_log_intermediate[%d] = %s\n' % (fgname, var_count, var_name)
                            var_id_lookup[short_var_name] = var_count
                            var_count += 1
                            log_s += '%s_log_intermediate[%d] = %s * %s\n' % (fgname, var_count, var_name, var_name)
                            var_count += 1
                        else:
                            current_count = var_id_lookup[short_var_name]
                            log_s += '%s_log_intermediate[%d] += %s\n' % (fgname, current_count, var_name)
                            log_s += '%s_log_intermediate[%d] += %s * %s\n' % (fgname, current_count+1, var_name, var_name)
                for current_count in var_id_lookup.values():
                    log_s += '%s_log_intermediate[%d] /= %d\n' % (fgname, current_count, niters-1)
                    log_s += '%s_log_intermediate[%d] /= %d\n' % (fgname, current_count+1, niters-1)
                    log_s += '%s_log_intermediate[%d] -= %s_log_intermediate[%d] * %s_log_intermediate[%d]\n' %(fgname, current_count+1, fgname, current_count, fgname, current_count)

        var_subset_count = 0
        for var_name in log_subset_list:
            if not var_name.startswith(DERIV_PREFIX):
                log_s += '%s_log_intermediate_subset[%d] = %s\n' %(fgname, var_subset_count, var_name)
                var_subset_count += 1

        compiler_params.constructor_code.append('\n%s_log_intermediate.resize(%d);\n' % (fgname, var_count))
        compiler_params.tf_global_code.append('\n%s_log_intermediate_len = (%d)\n' % (fgname, var_count))
        compiler_params.tf_global_code.append('\n%s_log_intermediate_subset_len = (%d)\n' % (fgname, var_subset_count))
        compiler_params.tf_global_code.append('\nconst_scale_bias_var_len = (%d)\n' % (len(compiler_params.const_vars)))
        s += '\n' + log_s
    else:
        fgname = 'f' if is_f else 'g'
        compiler_params.tf_global_code.append('\n%s_log_intermediate_len = 0\n' % (fgname))
        compiler_params.tf_global_code.append('\n%s_log_intermediate_subset_len = 0\n' % (fgname))
    
    return s

def create_loops(compiler_params, e, mid_str):
    ans = mid_str
    loop_vars = [x for x in e.all_nodes() if isinstance(x, LoopVar)]
    for loop_var in loop_vars:
        ans = loop_var.to_source_expr(compiler_params, indent('\n' + ans) + '\n', ans)
    return ans

def repeated_simplify_inplace(e, max_simplifications=5, remove_redundant=False):
    max_simplifications = 5
    n_simplify = 0
    e_current = ''
    while n_simplify < max_simplifications:
        e_before = e_current
        t1 = time.time()
        e = e.simplify(aggresive=remove_redundant)
        if remove_redundant:
            e = remove_redundant_exprs(e)
        print('simplify, round', n_simplify, time.time() - t1)
        n_simplify += 1

    return e

def to_source(e, compiler_params, info_d=None, do_copy=True, sanity_code=None):
    """
    Convert Expr to finalized source code, including variable and function declarations.
    """
    
    global __loop_cond
    
    vec_output_count = 3
    
    if isinstance(e, Compound):
        vec_output_count = len(e.children)

    if compiler_params.collect_loop_statistic:
        seen = set()
        e.collect_loop_nodes_recurse(compiler_params, seen=seen)
        e.calc_parents()
        for val in __loop_cond.values():
            for cond in val.values():
                cond.collect_loop_nodes_recurse(compiler_params, seen=seen)
                # do not use calc_parents because
                # we don't want to initialize parents to []
                for node in cond.all_nodes():
                    for child in node.children:
                        if isinstance(child, Expr):
                            if not hasattr(child, 'parents'):
                                child.parents = []
                            parents_id = [id(node) for node in child.parents]
                            if id(node) not in parents_id:
                                child.parents.append(node)
        compiler_params.for_loop_dict = global_for_loop_dict
        global DEFAULT_DO_LOG
        DEFAULT_DO_LOG = False
        for loop_key, loop_val in sorted(compiler_params.for_loop_dict.items()):
            current_len = None
            print(loop_key)
            print(loop_val.keys())
            accum_sum = None
            accum_square = None
            iter_keys = list(loop_val.keys())
            max_iter = numpy.max(iter_keys)
            loop_count = 0
            count_last_loop = True

            log_iters = [0, max_iter]
            

            if compiler_params.last_only:
                log_iters = [max_iter]
            elif compiler_params.subsample_loops is not None:
                log_iters = []
                #for i in range((max_iter+1) // compiler_params.subsample_loops):
                #    log_iters.append(i * compiler_params.subsample_loops)
                #if max_iter not in log_iters:
                #    log_iters.append(max_iter)
                for i in range(max_iter, -1, -compiler_params.subsample_loops):
                    log_iters.append(i)
            elif compiler_params.last_n is not None:
                log_iters = []
                for i in range(max_iter, max_iter-compiler_params.last_n, -1):
                    log_iters.append(i)
            elif compiler_params.first_n is not None:
                log_iters = []
                for i in range(compiler_params.first_n):
                    log_iters.append(i)
                log_iters.append(max_iter)
            elif compiler_params.first_n_no_last is not None:
                log_iters = []
                for i in range(compiler_params.first_n_no_last):
                    log_iters.append(i)
            elif compiler_params.mean_var_only:
                log_iters = []
            else:
                log_iters = list(numpy.arange(max_iter+1))

            if compiler_params.automate_loop_statistic:
                if loop_key.startswith(raymarching_loop_name_prefix):
                    log_iters = [max_iter]
                if loop_key.startswith(def_name_prefix):
                    if compiler_params.def_loop_log_last:
                        log_iters = [max_iter]
                    else:
                        log_iters = [0]

            if compiler_params.log_only_return_def_raymarching:
                if loop_key.startswith(raymarching_loop_name_prefix):
                    log_iters = [max_iter]
                elif loop_key.startswith(def_name_prefix):
                    log_iters = []
            
            compute_statistic = False
            if compiler_params.mean_var_only:
                compute_statistic = True
                
            if not loop_key.startswith(def_name_prefix):
                compiler_params.loop_log_scope[loop_key] = False
                
            
                
            print('log iters,', log_iters)

            assert sorted(iter_keys) == list(range(max_iter + 1))
            for iter_key, iter_val in loop_val.items():
                if current_len is None:
                    current_len = len(iter_val)
                    accum_sum = [0.0] * current_len
                    accum_square = [0.0] * current_len

                collect_sum = True
                
                # only require # of vars the same for each iter on REAL loops (not function def)
                if not loop_key.startswith(def_name_prefix):
                    try:
                        assert len(iter_val) == current_len, iter_key
                    except:
                        # Now that we're collecting loop info at the beginning of var creation
                        # loop var number should be the same
                        raise
                        assert iter_key == max_iter
                        collect_sum = False
                        count_last_loop = False
                        current_len = len(iter_val)

                if iter_key > 0:
                    # assume no cond applied for 1st iter
                    # and cond is always computed at the end of an iter
                    # cond computed at iter n will be applied to iter n+1
                    try:
                        cond = __loop_cond[loop_key][iter_key-1]
                    except:
                        cond = None
                else:
                    cond  = None

                global DEFAULT_FOR_LOOP_NAME
                global DEFAULT_FOR_LOOP_ITER
                default_for_loop_name = DEFAULT_FOR_LOOP_NAME
                default_for_loop_iter = DEFAULT_FOR_LOOP_ITER
                DEFAULT_FOR_LOOP_NAME = loop_key
                DEFAULT_FOR_LOOP_ITER = iter_key

                # for simplicity, assuming cond for 1st iter is always true
                if cond is not None:
                    # maybe don't need this
                    # everything is collected in global_for_loop_dict
                    # so do_log = False can be taken care of
                    # in the collect_sum if clause
                    #if iter_key - 1 not in log_iters:
                        #cond.disable_log_garbaged()
                    for i in range(current_len):
                        if i == 20:
                            i = 20
                        #if iter_val[i].is_loop_cond:
                        #    continue
                        if id(iter_val[i]) == id(__loop_cond[loop_key][iter_key]):
                            replace_cond = True
                        else:
                            replace_cond = False
                        old_do_log = iter_val[i].do_log
                        iter_val[i].do_log = False
                        # insert a select(cond, val, old_val)
                        # if filling with old_val, require all iters have the same number of variables
                        new_val = select(cond, iter_val[i], loop_val[iter_key-1][i])
                        new_val.do_log = old_do_log
                        new_val.loop_specified_name = '__masked' + iter_val[i].loop_specified_name

                        if hasattr(iter_val[i], 'parents'):
                            new_val.parents = list(iter_val[i].parents)
                            for parent in new_val.parents:
                                children_idx = [id(child) for child in parent.children]
                                try:
                                    child_idx = children_idx.index(id(iter_val[i]))
                                except:
                                    raise
                                parent.children[child_idx] = new_val
                                if False:
                                    # seems like the gen_attrs() already takes care of this?
                                    if isinstance(parent, Var):
                                        if id(parent.initial_value) == id(iter_val[i]):
                                            parent.initial_value = new_val
                                    elif isinstance(parent, BinaryOp):
                                        if id(parent.a) == id(iter_val[i]):
                                            parent.a = new_val
                                        if id(parent.b) == id(iter_val[i]):
                                            parent.b = new_val
                                    elif isinstance(parent, UnaryOp):
                                        if id(parent.a) == id(iter_val[i]):
                                            parent.a = new_val
                            iter_val[i].parents = [new_val]
                        else:
                            # for debug
                            pass

                        iter_val[i] = new_val
                        if replace_cond:
                            __loop_cond[loop_key][iter_key] = new_val

                if collect_sum:
                    # TODO: exist a potential bug
                    # should not collect sum if
                    # all component of it is garbage collected
                    # one way to address this is to
                    # collect sum after recognize nodes in compute graph
                    # after cond is inserted
                    loop_count += 1
                    for i in range(len(iter_val)):
                        if iter_key not in log_iters:
                            iter_val[i].do_log = False

                        if compute_statistic:
                            accum_sum[i] = accum_sum[i] + iter_val[i]
                            accum_square[i] = accum_square[i] + iter_val[i] * iter_val[i]
                            if sanity_code is not None and isinstance(iter_val[i], ConstExpr):
                                sanity_code = '%s = %s\n' % (iter_val[i].loop_specified_name, repr(iter_val[i])) + sanity_code

                DEFAULT_FOR_LOOP_NAME = default_for_loop_name
                DEFAULT_FOR_LOOP_ITER = default_for_loop_iter

            if count_last_loop:
                assert loop_count == max_iter + 1
            else:
                assert loop_count == max_iter

            if compute_statistic:
                for i in range(current_len):
                    accum_square[i] = accum_square[i] - accum_sum[i] * accum_sum[i] / loop_count

                # compute mean and variance
                if sanity_code is None:
                    # write statistic to vec_output if not provided by external source code
                    for i in range(current_len):
                        new_sum_node = Assign(GetItem(ArgumentArray(OUTPUT_ARRAY), 2 * i + vec_output_count), accum_sum[i])
                        new_sum_node.comment = 'loop sum for %s, %03d, max_iter %d#' % (loop_key, i, max_iter)
                        new_square_node = Assign(GetItem(ArgumentArray(OUTPUT_ARRAY), 2 * i + 1 + vec_output_count), accum_square[i])
                        new_square_node.comment = 'loop square for %s, %03d, max_iter %d#' %(loop_key, i, max_iter)
                        e.children.append(new_sum_node)
                        e.children.append(new_square_node)
                vec_output_count += 2 * current_len
        DEFAULT_DO_LOG = True

        if compiler_params.log_only_return_def_raymarching:
            # resolve which return values of raymarching loop and def should be logged
            seen = set()
            e.resolve_log_def_return(compiler_params, seen=seen)
        
        seen = set()
        e.resolver_interleaved_loop(compiler_params, seen=seen)
                        
    compiler_params.tf_global_code.append(OUTPUT_ARRAY + '_len = %d' % vec_output_count)

    
    if compiler_params.simplify_compute_graph:
        e = remove_redundant_exprs(e)
        print('remove redundant exprs finished')

        e = repeated_simplify_inplace(e, remove_redundant=compiler_params.collect_loop_statistic or compiler_params.robust_simplification)
        print('repeated simplify finished')
    e.calc_parents()
    print("calculate_parents_after_simplify_finished")
    print(compiler_params.rng_counter)
    print("printed rng_counter")

    rng_counter = compiler_params.rng_counter
    print('do copy is', do_copy)
    if do_copy:
        c0 = compiler_params
        for_loop_dict = compiler_params.for_loop_dict
        compiler_params.for_loop_dict = {}
        compiler_params = copy.deepcopy(compiler_params)
        compiler_params.for_loop_dict = for_loop_dict
        compiler_params.constructor_code = c0.constructor_code
        compiler_params.tf_global_code = c0.tf_global_code
    print("after do_copy", do_copy)
    compiler_params.root = True
    compiler_params.mode = MODE_SIDE_EFFECTS
    print("before resetting compiler parameters")
    compiler_params.reset()
    print("successfully reset compiler parameters")


    print("entering to_source_nonfinal")
    f = to_source_nonfinal(e, compiler_params, can_log_intermediates=True, is_f=True)
    print("to_source_nonfinal finished")
    if sanity_code is not None:
        f = f + '\n' + sanity_code + '\n'
    if compiler_params.trace:
        f += '\nprint("\\n")\n'

    

    f_return = '\n' + 'return ' + e.to_source(compiler_params.as_mode(MODE_VARNAME))
    unknown_array = DEFAULT_ARGUMENT_ARRAY_NAME
    f_declare = 'def f(' + unknown_array + ', f_log_intermediate, vec_output, f_log_intermediate_subset=[], texture_maps=[]):'

    f = f_declare + '\n' + indent(f + f_return) + '\n'
    if info_d is not None:
        info_d['f_lines'] = f.count('\n')

    class_declares = ''
    
    

    

    c = f
    c = SOURCE_PY_FILE_BEGIN + '\n'.join(compiler_params.tf_global_code) + '\n' + c


    return c

def to_expr(const_or_expr):
    """
    Convert constant or expression typically to Expr type but with special cases for handling None or ConstExpr.
    """
    if isinstance(const_or_expr, int_types + float_types + (str,)):
        return ConstExpr(const_or_expr)
    elif isinstance(const_or_expr, type(None)):
        return None
    elif isinstance(const_or_expr, Expr):
        return const_or_expr
    elif isinstance(const_or_expr, tuple):
        return Tuple(const_or_expr)

    raise ValueError('unknown case: ', const_or_expr)

def indent(s, count=4):
    lines = s.split('\n')
    return '\n'.join(' '*count + line for line in lines)

#redundant_index = 0

def remove_redundant_exprs(e):
    """
    Return copy of Expr graph with redundant Exprs consolidated into a single instance.
    """
    
    repr_to_expr = {}

    repr_cache = {}

    all_nodes = e.all_nodes_dfs()
    
    len_nodes = len(all_nodes)
    for (j, node) in enumerate(all_nodes):
        
        len_children = len(node.children)
        for (i, child) in enumerate(node.children):
            if isinstance(child, Expr):
                r = child.repr(False, repr_cache)
                seen = r in repr_to_expr
                
                if seen:
                    node.children[i] = repr_to_expr[r]
                if not seen:
                    repr_to_expr[r] = child
    e.calc_parents()
    print('finished calculate_parents')


    return e


def identical(a, b):
    """
    Check whether either Expr or list of Exprs a and b are identical (cast elements to Expr using to_expr() if needed).
    """
    if isinstance(a, Expr):
        return a.identical(b)
    elif isinstance(a, (list, tuple)):
        if len(a) != len(b):
            return False
        for i in range(len(a)):
            av = a[i]
            bv = b[i]
            if not isinstance(av, Expr):
                av = to_expr(av)
            if not isinstance(bv, Expr):
                bv = to_expr(bv)
            if not av.identical(bv):
                return False
        return True

def intersect_exprs(La, Lb):
    """
    Intersect two lists of Exprs.
    """
    b_unique_strs = set([node.unique_str() for node in Lb])
    return [node for node in La if node.unique_str() in b_unique_strs]

def union_exprs(La, Lb):
    """
    Union two lists of Exprs.
    """
    b_strs = set([node.unique_str() for node in Lb])
    a_extra_nodes = [node for node in La if node.unique_str() not in b_strs]
    return a_extra_nodes + Lb

def exclude_exprs(La, Lb):
    """
    Returns list that's in a, but not in b
    """
    b_unique_strs = set([node.unique_str() for node in Lb])
    return [node for node in La if node.unique_str() not in b_unique_strs]

def infix_repr(e):
    """
    Convert Expr or list of Expr to human-readable, infix, C-like code str.
    """
    if isinstance(e, (tuple, list)):
        return '[' + ', '.join(infix_repr(x) for x in e) + ']'
    c = CompilerParams()
    c.mode = MODE_ALWAYS_INLINE
    return e.to_source(c)

def linenos_from_frame(current_frame, depth=10):
    ans = []
    ans.append(current_frame.f_lineno)
    for i in range(depth):
        current_frame = current_frame.f_back
        if current_frame is None:
            break
        ans.append(current_frame.f_lineno)
    return ans

def running_sum(a, b):
    """
    Add Expr a and b, unless either is None, in which case, return the other (None is treated as 0).
    """
    if a is None:
        return b
    elif b is None:
        return a
    return a + b

class Expr:
    """
    Expression type.

    Attributes:
    children --- A list of children for the expression (of any type, but AST nodes are of type Expr).
    dtype --- Type of expression, one of INT_TYPE or REAL_TYPE ('double').
    log_intermediates_rank ---- Used to identify which nodes to log
    log_intermediates_subset_rank ---- Workaround for auxiliary features
    for_loop_name --- A hack that records whether the current expr is within a for loop, and the name of the loop
    for_loop_iter --- If the expr is within a loop, a hack that records which iter it's in now
    loop_specified_name --- If not None, use this name as varname
    comment --- Add at the end of the line as comment, for extra information or debugging purpose
    """

    def __init__(self, frame_depth=2):
        self.children = []
        self.recurse_to_source_indices = None
        current_frame = inspect.currentframe()
        self.frame_lineno = linenos_from_frame(current_frame)
        self.log_intermediates_rank = log_intermediates_rank
        self.log_intermediates_subset_rank = log_intermediates_subset_rank
        self.for_loop_name = DEFAULT_FOR_LOOP_NAME
        self.for_loop_iter = DEFAULT_FOR_LOOP_ITER
        self.is_loop_cond = DEFAULT_IS_LOOP_COND
        self.loop_specified_name = None
        self.comment = ''
        self.do_log = DEFAULT_DO_LOG
        self.const_scale_bias = False
        self.garbage_collected = True
        self.to_source_varname = None
        if self.for_loop_name is not None:
            global global_for_loop_dict
            global global_for_loop_id
            assert self.for_loop_iter is not None
            if self.for_loop_name not in global_for_loop_dict:
                global_for_loop_dict[self.for_loop_name] = {}
                global_for_loop_id[self.for_loop_name] = {}
            if self.for_loop_iter not in global_for_loop_dict[self.for_loop_name]:
                global_for_loop_dict[self.for_loop_name][self.for_loop_iter] = []
                global_for_loop_id[self.for_loop_name][self.for_loop_iter] = []
            n = len(global_for_loop_dict[self.for_loop_name][self.for_loop_iter])
            self.loop_specified_name = self.for_loop_name + '_' + str(self.for_loop_iter) + '_%03d'%n
            global_for_loop_dict[self.for_loop_name][self.for_loop_iter].append(self)
            global_for_loop_id[self.for_loop_name][self.for_loop_iter].append(id(self))

    def disable_log_garbaged(self):
        # Any var with loop_name and loop_var
        # but is regarded as garbage (garbage_collected = True)
        # means that they were not part of the compute graph before
        # therefore we recognize them as being part of the cond
        self.do_log = False
        for child in self.children:
            if isinstance(child, Expr) and child.for_loop_name is not None and child.for_loop_iter is not None and child.garbage_collected:
                child.disable_log_same_iter()

    def collect_loop_nodes_recurse(self, compiler_params, seen=None):
        # mark any loop var that is part of the final compute graph
        if seen is None:
            seen = set()
        id_self = id(self)
        if id_self in seen:
            return
        seen.add(id_self)
        self.garbage_collected = False
        if False:
            if self.for_loop_name is not None or self.for_loop_iter is not None:
                if not self.for_loop_name is not None and self.for_loop_iter is not None:
                    print('for loop build error', self.for_loop_name, self.for_loop_iter)
                if self.for_loop_name not in compiler_params.for_loop_dict:
                    compiler_params.for_loop_dict[self.for_loop_name] = {}
                if self.for_loop_iter not in compiler_params.for_loop_dict[self.for_loop_name]:
                    compiler_params.for_loop_dict[self.for_loop_name][self.for_loop_iter] = []
                n = len(compiler_params.for_loop_dict[self.for_loop_name][self.for_loop_iter])
                if self.loop_specified_name is None:
                    self.loop_specified_name = self.for_loop_name + '_' + str(self.for_loop_iter) + '_%03d'%n
                if self.is_loop_cond:
                    self.loop_specified_name = '_cond' + self.loop_specified_name
                compiler_params.for_loop_dict[self.for_loop_name][self.for_loop_iter].append(self)
        for child in self.children:
            if isinstance(child, Expr):
                child.collect_loop_nodes_recurse(compiler_params, seen)
                
    def resolve_log_def_return(self, compiler_params, seen=None):
        if seen is None:
            seen = set()
        id_self = id(self)
        if id_self in seen:
            return
        
        # only process child node if all its parents has already been processed
        for pa in self.parents:
            if id(pa) not in seen:
                return
            
        global last_for_loop_name
        
        if self.for_loop_name is not None:
            if self.for_loop_name.startswith(def_name_prefix):
                # trace in tagged def
                # assuming already set do_log to False
                # if its parent has node outside the current function call
                # do_log set the same to the parent
                if hasattr(self, 'parents'):
                    for pa in self.parents:
                        if pa.for_loop_name == self.for_loop_name and pa.for_loop_iter == self.for_loop_iter:
                            continue
                        else:
                            if pa.for_loop_name is None or pa.for_loop_name.startswith(def_name_prefix):
                                self.do_log = self.do_log or pa.do_log
                            else:
                                self.do_log = self.do_log or (pa.do_log and compiler_params.loop_log_scope[pa.for_loop_name])
                            
            else:
                # assuming do_log already set correctly as if no interleaving loops exist
                # if any variable is used outside the current loop
                # the loop_log_scope should be set to be the scope of the caller
                # however, if caller itself is also a loop variable
                # should note that the current do_log for caller is not the actual do_log, should be also considering the scope of the caller
                if hasattr(self, 'parents'):
                    for pa in self.parents:
                        if pa.for_loop_name == self.for_loop_name:
                            continue
                        else:
                            
                            if pa.for_loop_name is None or pa.for_loop_name.startswith(def_name_prefix):
                                compiler_params.loop_log_scope[self.for_loop_name] = compiler_params.loop_log_scope[self.for_loop_name] or pa.do_log
                            else:
                                compiler_params.loop_log_scope[self.for_loop_name] = compiler_params.loop_log_scope[self.for_loop_name] or (pa.do_log and compiler_params.loop_log_scope[pa.for_loop_name])
                       
                    
        seen.add(id_self)
                
        for child in self.children:
            if isinstance(child, Expr):
                child.resolve_log_def_return(compiler_params, seen)
                
    def resolver_interleaved_loop(self, compiler_params, seen=None):
        if seen is None:
            seen = set()
        id_self = id(self)
        if id_self in seen:
            return
        seen.add(id_self)
        
        global last_for_loop_name
        
        if (self.for_loop_name is not None) and (not self.for_loop_name.startswith(def_name_prefix)):
                                        
            if self.for_loop_name != last_for_loop_name:
                last_for_loop_name = self.for_loop_name
            
            self.do_log = self.do_log and compiler_params.loop_log_scope[self.for_loop_name]
            
        for child in self.children:
            if isinstance(child, Expr):
                child.resolver_interleaved_loop(compiler_params, seen)

    def __copy__(self):
        """
        Create a shallow copy which does not share the children list.
        """
        cls = self.__class__
        ans = cls.__new__(cls)
        ans.__dict__.update(self.__dict__)
        ans.children = list(ans.children)
        return ans

    def subs(self, source, dest, copy=True):
        """
        Return a deep copy of self (unless copy is False) that has source (Expr) replaced with dest (Expr), recursively.
        """
        if copy:
            self = copy.deepcopy(self)
        source_str = source.unique_str()
        self.calc_parents()
        nsubs = 0
        for node in self.all_nodes():
            node_id = id(node)
            node_str = node.unique_str()
            parents = node.parents
            if node_str == source_str:
                for parent in parents:
                    for i in range(len(parent.children)):
                        if id(parent.children[i]) == node_id:
                            parent.children[i] = dest
                            nsubs += 1
     
        return self

    
    def differentiate_wrt(self):
        """
        True iff self is a variable that can be differentiated with respect to.
        """
        return True

    def contains_unknown_array(self):
        """
        Whether any sub-node (including the current node) is an input unknown array.
        """
        return any([is_unknown_array(node) for node in self.all_nodes()])


    def unique_str(self):
        #a = copy.deepcopy(self)
        #a.clear_parents()
        #return repr(a)
        ans = self.repr(False)
        #ans = ans.replace('Gaussian_RNG::get_g', 'Gaussian_RNG::get_r').replace('Gaussian_RNG::get_b', 'Gaussian_RNG::get_r')
        return ans

    def identical(self, b):
        """
        Returns bool for whether self and b are identical expressions without attempting any simplification.
        """
        return self.unique_str() == b.unique_str()

    def simplify(self, seen=None, aggresive=False):
        """
        Simplifies the given Expr in place (recursively), returning the simplified Expr.
        If aggresive: (it's actually a more robust simplification), setting this flag so that the previous result will not be messed up
        """
        if seen is None:
            if not aggresive:
                seen = set()
            else:
                seen = {}
        id_self = id(self)
        if id_self in seen:
            if not aggresive:
                return self
            else:
                return seen[id_self]
        if not aggresive:
            seen.add(id_self)
        self.simplify_children(seen, aggresive=aggresive)
        ans = self.simplify_impl()
        if aggresive:
            seen[id_self] = ans
        return ans

    def simplify_impl(self):
        """
        Simplifies the given Expr but not its children in place, returning the simplified Expr.
        """
        return self

    def simplify_children(self, seen, aggresive=False):
        """
        Simplifies the children of the given Expr in place.
        """
        for (i, child) in enumerate(self.children):
            if hasattr(child, 'simplify'):
                if id(child) not in seen:
                    cp = child.simplify(seen, aggresive=aggresive)
                    if not isinstance(cp, Expr) and cp is not None:
                        raise ValueError('Bad type for simplified expression', (cp, type(cp), child))
                    self.children[i] = cp
                else:
                    if aggresive:
                        self.children[i] = seen[id(child)]

    

    def is_unknown_getitem(self):
        return isinstance(self, GetItem) and is_unknown_array(self.array)

    def clear_parents(self):
        for node in self.all_nodes():
            if hasattr(node, 'parents'):
                del node.parents

    def calc_parents(self):
        for node in self.all_nodes():
            node.parents = []
        print("all nodes parents set null")
        for node in self.all_nodes():
            for child in node.children:
                if isinstance(child, Expr):
                    child.parents.append(node)

    def is_constant(self):
        """
        Is this a constant expression? (ConstExpr or a tree containing operators, calls, and constants)
        """
        return all(isinstance(node, (ConstExpr, BinaryOp, UnaryOp, Call)) for node in self.all_nodes())

    def check_acyclic(self, allow_visit=None):
        """
        Raise an exception if there is a cycle in the Expr graph. Otherwise, return self.
        """
        seen = set()
        ans = []
        def visit(node, parents):
            if id(node) in parents:
                raise ValueError('cycle detected')
            if id(node) in seen:
                return
            seen.add(id(node))
            parents = parents | set([id(node)])
            for child in node.children:
                if isinstance(child, Expr):
                    if (allow_visit is None or allow_visit(node, child)):
                        visit(child, parents)
            ans.append(node)
        visit(self, set())
        return self

    def all_nodes_generator(self):
        """
        A generator yielding all nodes in depth-first order.
        """
        seen = set()
        next = [self]
        while len(next):
            current = next.pop()
            id_current = id(current)
            if not id_current in seen:
                seen.add(id_current)
                if isinstance(current, Expr):
                    yield current
                    next.extend(current.children)

    def all_nodes_dfs(self, allow_visit=None, order='dfs'):
        """
        Recursive nodes including self (Expr subclasses only), in depth-first order, bottom up.

        This order implies that Exprs are visited in dependency order, so an Expr is visited before any parent that depends on it.
        """
        if order == 'dfs':
            order_normal = True
        elif order == 'dfs_random':
            order_normal = False
        else:
            raise ValueError('unknown order %r' % order)
        seen = set()
        ans = []
        def visit(node):
            if id(node) in seen:
                return
            seen.add(id(node))
            for child in (node.children if order_normal else util.shuffled(node.children)):
                if isinstance(child, Expr):
                    if (allow_visit is None or allow_visit(node, child)):
                        visit(child)
            ans.append(node)
        visit(self)
        return ans

    def all_nodes_order(self, order):
        if order in ['dfs', 'dfs_random']:
            return self.all_nodes_dfs(order=order)
        elif order == 'bfs':
            return self.all_nodes()
        else:
            raise ValueError('unknown order')

    def all_nodes(self, allow_visit=None):
        """
        Recursive nodes including self (Expr subclasses only), in breadth-first order, top down.

        If allow_visit is not None then allow_visit(parent, child) should give a bool for whether to visit the given child.
        """
        ans = [self]
        seen = set([id(self)])
        def visit(node):
            visit_next = []
            for child in node.children:
                if isinstance(child, Expr):
                    if id(child) not in seen and (allow_visit is None or allow_visit(node, child)):
                        ans.append(child)
                        seen.add(id(child))
                        visit_next.append(child)
            for child in visit_next:
                visit(child)
        visit(self)
        return ans
    

    def either_name(self, compiler_params):
        """
        Get variable
        """
        return self.var_name(compiler_params)

    def var_name(self, compiler_params):
        # a hack to count the number of const bias and scale vars
        if self.for_loop_name is not None or self.for_loop_iter is not None:
            if self.loop_specified_name is None:
                print('no loop name given', self.for_loop_name, self.for_loop_iter)
        remove_linear_fail = False
        
        if isinstance(self, GetItem) and (not compiler_params.log_getitem):
            self.do_log = False

        if not compiler_params.chron_order:
            # A sanity check to see if a node is visited at least after one of its parent is visited
            # disable the sanity check if in chron_order mode, now the traversal is from bottom to up
            success = False
            for parent in self.parents:
                if id(parent) in compiler_params.name_to_order:
                    success = True
                    break
            if not success:
                if not isinstance(self.parents[0], Assign):
                    raise
        else:
            # anither sanity check: see if a node is visited after all of its children are visited
            success = True
            for child in self.children:
                if isinstance(child, Expr):
                    if not id(child) in compiler_params.name_to_order:
                        if not isinstance(child, (ArgumentArray, ConstExpr)):
                            success = False
                            break
            if not success:
                raise

        if compiler_params.one_hop_parent:
        #if False:
            #print("checking whether logging parents")
            if self.do_log:
                #print('found parents:', len(self.parents))
                for parent in self.parents:
                    if parent.do_log:
                        #print('parent logged')
                        self.do_log = False
                        break

        if self.do_log:
            if isinstance(self, BinaryOp):
                if self.op in ['+', '-', '*']:
                    if isinstance(self.a, ConstExpr):
                        if self.b.do_log or self.b.const_scale_bias:
                            self.const_scale_bias = True
                        else:
                            remove_linear_fail = True
                    elif isinstance(self.b, ConstExpr):
                        if self.a.do_log or self.a.const_scale_bias:
                            self.const_scale_bias = True
                        else:
                            remove_linear_fail = True
                    #if isinstance(self.a, ConstExpr) or isinstance(self.b, ConstExpr):
                    #    self.const_scale_bias = True
                if self.op == '/' and isinstance(self.b, ConstExpr):
                    #self.const_scale_bias = True
                    if self.a.do_log or self.a.const_scale_bias:
                        self.const_scale_bias = True
                    else:
                        remove_linear_fail = True
            if self.const_scale_bias:
                self.do_log = False

        ans = compiler_params.get_varname(getattr(self, 'name', ''), id(self), self.dtype, rank=self.log_intermediates_rank, subset_rank=self.log_intermediates_subset_rank, loop_specified_name=self.loop_specified_name, do_log=self.do_log)
        self.to_source_varname = ans
        if remove_linear_fail:
            print("remove linear failed,", ans)
        

        if self.const_scale_bias:
            if ans not in compiler_params.const_vars:
                compiler_params.const_vars.append(ans)

        return ans


    def to_source_expr(self, compiler_params):
        """
        Convert a side-effect free expression to source code.
        """
        raise NotImplementedError(self.__class__)

    

    def has_param_parents(self):
        """
        Return bool indicating whether any of the parents of self are VarParam instances.
        """
        return any([isinstance(parent, VarParam) for parent in self.parents])

    def debug(self, compiler_params):
        pass

    def debug_return(self, compiler_params, retval):
        if retval is None:
            
            raise ValueError
        
        return retval

    def is_inline(self, compiler_params):
        if compiler_params.mode in [MODE_INLINE, MODE_ALWAYS_INLINE]:
            return self.dtype == INT_TYPE
        return False

    def to_source_inline(self, compiler_params):
        if compiler_params.mode in [MODE_VARNAME, MODE_SAMPLE_PROBLEM, MODE_INLINE, MODE_ALWAYS_INLINE]:
            if compiler_params.mode == MODE_SAMPLE_PROBLEM and compiler_params.root:
                return ''
            return self.to_source_impl(compiler_params.deroot().as_mode(MODE_INLINE if compiler_params.mode != MODE_ALWAYS_INLINE else MODE_ALWAYS_INLINE))
        elif compiler_params.mode == MODE_SIDE_EFFECTS:
            return ''
        else:
            raise ValueError('unknown mode', compiler_params.mode)
        

    def to_source(self, compiler_params):
        self.debug(compiler_params)
        if self.is_inline(compiler_params):
            ans = self.to_source_inline(compiler_params)
        else:
            ans = self.to_source_impl(compiler_params)
            ans = self.debug_return(compiler_params, ans)
        return ans

    def to_source_recurse(self, compiler_params, ans):
        if not compiler_params.recurse:
            return ''
        cp = compiler_params.deroot().as_mode(MODE_SIDE_EFFECTS)
        
        children = [child for child in self.children if isinstance(child, Expr)]
        if self.recurse_to_source_indices is not None:
            children = children[self.recurse_to_source_indices]
        prepend = ''
        for child in children: #[::-1]:
            # TODO: Can we change back the next line?
            if not cp.recurse:
                sub = child.to_source_recurse(compiler_params, '')
                if len(sub):
                    prepend = prepend + '\n' + sub #ans = sub + '\n' + ans
            sub = child.to_source(cp)
            if len(sub):
                prepend = prepend + '\n' + sub #ans = sub + '\n' + ans
        return prepend + '\n' + ans
        """
        if not cp.recurse:
            for child in children[::-1]:
                sub = child.to_source_recurse(compiler_params, '')
                if len(sub):
                    ans = sub + '\n' + ans
        """
        return ans
    

    def to_source_rhs(self, compiler_params, ordinary_value):

        side_effectsL = []

        rhs = ordinary_value
        ans = (rhs, '\n'.join(side_effectsL))
        
        return ans

    def concat_side_effects(self, compiler_params, ans, side_effects):
        if len(side_effects.strip()):

            ans = side_effects + '\n' + ans
            
        return ans

    def statement_id(self, compiler_params):
        """
        Get an "id" key for the set CompilerParams.statement_ids.
        """
        return (True, id(self)) 

    def to_source_impl(self, compiler_params):
        """
        Convert to source code in the given language.

        In the base class this assumes a side-effect free expression is used, and implemented in to_source_expr().
        However, this behavior can be overridden by implementing a different to_source() in subclasses.
        """
        if compiler_params.mode == MODE_VARNAME:
            return self.either_name(compiler_params)
        elif compiler_params.mode in [MODE_SAMPLE_PROBLEM, MODE_INLINE, MODE_ALWAYS_INLINE]:
            if compiler_params.root and compiler_params.mode != MODE_ALWAYS_INLINE:
                return ''
            else:
               
                key = id(self)
                if key in compiler_params.cache_to_source:
                    return compiler_params.cache_to_source[key]
                ans = self.to_source_expr(compiler_params.deroot())
                compiler_params.cache_to_source[key] = ans
                return ans
        elif compiler_params.mode == MODE_SIDE_EFFECTS:
            
            self_id = self.statement_id(compiler_params)
            if self_id in compiler_params.statement_ids and no_generate_duplicates:
                return ''
            compiler_params.statement_ids.add(self_id)
            if not compiler_params.chron_order:
                (rhs, side_effects) = self.to_source_rhs(compiler_params, self.to_source_expr(compiler_params.deroot().as_mode(MODE_VARNAME)))
                
                ans = ''

                ans += '\n' + side_effects + '\n'
                ans += '\n' + self.to_source_recurse(compiler_params, '')
                
                self.to_source_recurse(compiler_params, '')
            else:
                ans = self.to_source_recurse(compiler_params, '')
                (rhs, side_effects) = self.to_source_rhs(compiler_params, self.to_source_expr(compiler_params.deroot().as_mode(MODE_VARNAME)))

            def ljust(s):
                return (s).ljust(50)

            comment_symbol = ' # '

            rhs_comment = comment_symbol + self.comment + ' Expr, id: ' + str(id(self)) + ', Linenos for Expr: ' + str(self.frame_lineno) + ', Linenos for codegen: ' + str(linenos_from_frame(inspect.currentframe()))

            if self.dtype != VOID_TYPE:
                this_line = self.either_name(compiler_params) + ' = ' + rhs + rhs_comment

                ans += '\n' + ljust(this_line)
            else:
                ans += '\n' + ljust(rhs) + rhs_comment
                
            
            return ans
        else:
            raise ValueError('unhandled mode', compiler_params.mode)

    #def to_initializer_source(self, compiler_params, is_instance):
    #    """
    #    Convert to source code for initializer, or empty string if no initializer.
    #
    #    Here is_instance is whether variables should be class instance variables (if False, function variables).
    #    """
    #    return ''

    def repr(self, extra_info=True, cache=None, infix=False):

        if infix:
            return infix_repr(self)
        if cache is None:
            cache = dict()
        cache_key = id(self)

        if cache_key in cache:
            extra_s = ''
            if extra_info:
                extra_s = 'id: ' + str(id(self)) + ', '

            return self.__class__.__name__ + '(%srepeated %s)' % (extra_s, cache[cache_key])

        line_length = 80
        sub_repr = [x.repr(extra_info, cache) if hasattr(x, 'repr') else repr(x) for x in self.children]
        sub_repr_len = sum([len(x) for x in sub_repr])


        if extra_info:
            if hasattr(self, 'parents'):        # If calc_parents() called, include extra info in repr().
                sub_repr = ['parents: [' + ', '.join(str(id(p)) for p in self.parents) + ']'] + sub_repr
            sub_repr = ['id: ' + str(id(self))] + sub_repr
        
        if sub_repr_len < line_length and all([not hasattr(node, 'children') or node.children == [] or isinstance(node, ConstExpr) for node in self.children]):
            ans = self.__class__.__name__ + '(' + (', '.join(sub_repr)) + ')'
        else:
            ans = self.__class__.__name__ + '(\n' + indent(',\n'.join(sub_repr)) + '\n)'


        cache[cache_key] = hashlib.md5(ans.encode('utf-8')).hexdigest()


        return ans

    def __repr__(self):
        return self.repr()

    def __str__(self):
        return self.__class__.__name__

    def __iadd__(self, other):
#        print('__iadd__ called', self, other)
        assert self.reduce is None
        self.reduce = '+'
        self.reduce_value = to_expr(other)
        return self

    def is_seq(self, other):
        return hasattr(self, '__len__') or hasattr(other, '__len__')

    def __add__(self, other):
        if self.is_seq(other):
            return numpy.add(self, other)
        return BinaryOp('+', self, other)

    def __radd__(self, other):
        if self.is_seq(other):
            return numpy.add(self, other)
        return BinaryOp('+', other, self)

    def __mul__(self, other):
        if self.is_seq(other):
            return numpy.multiply(self, other)
        return BinaryOp('*', self, other)

    def __rmul__(self, other):
        if self.is_seq(other):
            return numpy.multiply(self, other)
        return BinaryOp('*', other, self)

    def __mod__(self, other):
        if self.is_seq(other):
            return numpy.mod(self, other)
        return BinaryOp('%', self, other)

    def __rmod__(self, other):
        if self.is_seq(other):
            return numpy.mod(other, self)
        return BinaryOp('%', other, self)

    def __truediv__(self, other):
        if self.is_seq(other):
            return numpy.true_divide(self, other)
        return BinaryOp('/', self, other)

    def __rtruediv__(self, other):
        if self.is_seq(other):
            return numpy.true_divide(other, self)
        return BinaryOp('/', other, self)

    def __floordiv__(self, other):
        if self.is_seq(other):
            return numpy.floor_divide(self, other)
        return BinaryOp('/', self, other)

    def __rfloordiv__(self, other):
        if self.is_seq(other):
            return numpy.floor_divide(other, self)
        return BinaryOp('/', other, self)
    

    def __sub__(self, other):
        if self.is_seq(other):
            return numpy.subtract(self, other)
        return BinaryOp('-', self, other)

    def __rsub__(self, other):
        if self.is_seq(other):
            return numpy.subtract(other, self)
        return BinaryOp('-', other, self)

    def __neg__(self):
        return UnaryOp('-', self)

    def __invert__(self):
        return UnaryOp('~', self)

    def __pos__(self):
        return self

    def __pow__(self, other):
        if self.is_seq(other):
            return numpy.power(self, other)
        if isinstance(other, int_types + float_types):
            if other == 1:
                return self
            elif other == 0:
                return 1.0
        return BinaryOp('**', self, other)

    def __rpow__(self, other):
        if self.is_seq(other):
            return numpy.power(other, self)
        return BinaryOp('**', other, self)

    def __lt__(self, other):
        return BinaryOp('<', self, other)

    def __le__(self, other):
        return BinaryOp('<=', self, other)

    def __eq__(self, other):
        return equal(self, other)

    def __ne__(self, other):
        return nequal(self, other)

    def __gt__(self, other):
        return BinaryOp('>', self, other)

    def __ge__(self, other):
        return BinaryOp('>=', self, other)

    def __abs__(self):
        return Func('abs',
                    tf_name = 'tf_np_wrapper("abs")')(self)

class AlwaysInlineExpr(Expr):
    """
    Expression that is always generated inline. Subclasses should implement to_source_impl() method.
    """
    def to_source_impl(self, compiler_params):
        raise NotImplementedError

    def is_inline(self, compiler_params):
        return True

class ConstExpr(AlwaysInlineExpr):

    def __init__(self, value):
        super().__init__()
        self.value = value
        if isinstance(value, int_types):
            self.dtype = INT_TYPE
        elif isinstance(value, float_types):
            self.dtype = REAL_TYPE
        elif isinstance(value, ConstExpr):
            self.value = value.value
            self.dtype = value.dtype
        elif isinstance(value, str):
            self.value = value
            self.dtype = STR_TYPE
        else:
            raise ValueError('unknown type')
        self.children = [self.value]


    def differentiate_wrt(self):
        if isinstance(self.value, str):
            return False
        return True


    def repr(self, extra_info=True, cache=None):
        return str(self.value)

    def __str__(self):
        return super().__str__() + '(' + str(self.value) + ')'

    def to_source_impl(self, compiler_params):
        return repr(self)

#    to_source_inline = to_source_impl

def gen_attrs(assign_lambdas):
    ans = []
    for (i, assign_lambda) in enumerate(assign_lambdas):
        def append_setter(i, assign_lambda):
            def setter(self, value):
#                print('setting child ', i, 'value', value)
                self.children[i] = assign_lambda(value)
#                print('after assignment, children=', self.children)
#                print('after assignment, self=', self)
#                print('after assignment, id(self)=', id(self))
            ans.append(property(lambda self: self.children[i], setter))
        append_setter(i, assign_lambda)
    return ans

class Var(Expr):
    """
    A variable that is assigned initially, and possibly added to with a reduction expression.
    """
    def __init__(self, name, initial_value=0.0, reduce=None, reduce_value=None, is_argument=False):
        """
        Here reduce is a string for the reduction operator (e.g. '+') or None if no reduction.
        """
        super().__init__()
        self.children = [str(name), to_expr(initial_value), reduce, reduce_value]
        self.dtype = self.initial_value.dtype
        self.is_argument = is_argument


    (name, initial_value, reduce, reduce_value) = gen_attrs([str, to_expr, str, to_expr])

    

    def loop_vars(self):
        return [x for x in self.reduce_value.all_nodes() if isinstance(x, LoopVar)] #[::-1]

    def to_source_impl(self, compiler_params):
        #self.debug(compiler_params)
        #full_name = compiler_params.get_varname(self.name, self.name, self.dtype)
        compiler_params.is_Var = True
        if not compiler_params.chron_order:
            full_name = self.either_name(compiler_params)
        compiler_params.is_Var = False
        if compiler_params.mode == MODE_VARNAME:
            if compiler_params.chron_order:
                full_name = self.either_name(compiler_params)
            return full_name
        elif compiler_params.mode == MODE_ALWAYS_INLINE:
            if self.reduce is not None:
                raise ValueError('cannot convert reduction to source code in mode MODE_ALWAYS_INLINE')
            return self.initial_value.to_source(compiler_params)
        elif compiler_params.mode in [MODE_SAMPLE_PROBLEM, MODE_INLINE]:
            if compiler_params.chron_order:
                full_name = self.either_name(compiler_params)
            if compiler_params.mode == MODE_ALWAYS_INLINE:
                return full_name
            return ''
        elif compiler_params.mode == MODE_SIDE_EFFECTS:
            if self.is_argument:
                return ''
            self_id = self.statement_id(compiler_params)
            if self_id in compiler_params.statement_ids and no_generate_duplicates:
                return ''
            compiler_params.statement_ids.add(self_id)
            if self.reduce is not None:
                if compiler_params.chron_order:
                    full_name = self.either_name(compiler_params)
                loop_vars = self.loop_vars()
                iv_side_effects = self.initial_value.to_source(compiler_params)
                iv_rhs = self.initial_value.to_source(compiler_params.deroot().as_mode(MODE_VARNAME))
                ans_children = self.to_source_recurse(compiler_params, '')
                ans_self = full_name + ' += ' + self.reduce_value.to_source(compiler_params.deroot().as_mode(MODE_VARNAME))

                ans = ans_children + '\n' + ans_self
                
                for loop_var in loop_vars:
                    ans = loop_var.to_source_expr(compiler_params, indent('\n' + ans) + '\n', ans)
                this_line = full_name + ' = ' + iv_rhs
                
                ans = iv_side_effects = '\n' + this_line + '\n' + ans

                return ans
            else:
                if not compiler_params.chron_order:
                    ans = self.var_initializer(compiler_params.as_mode(MODE_VARNAME)) 
                    ans = self.to_source_recurse(compiler_params, ans)
                else:
                    ans = self.to_source_recurse(compiler_params, '')
                    full_name = self.either_name(compiler_params)
                    ans += self.var_initializer(compiler_params.as_mode(MODE_VARNAME))
                if compiler_params.trace:
                    ans += 'print("' + full_name + ': ",' + full_name + ')\n'
                return ans
        else:
            raise ValueError('unhandled mode', compiler_params.mode)

    def arg_declare(self, compiler_params):
        return self.either_name(compiler_params)

    def var_initializer(self, compiler_params):
        if compiler_params.mode in [MODE_SAMPLE_PROBLEM, MODE_INLINE, MODE_ALWAYS_INLINE]:
            name = self.name
            declare = ''
        else:
            name = self.either_name(compiler_params)
            declare = ''
        
        (initial_value, side_effects) = self.to_source_rhs(compiler_params, self.initial_value.to_source(compiler_params))

        
        ans = ''

        comment_symbol = '# '
        ans += '\n' + comment_symbol + 'Side effects (forward, variable initializer)\n' + side_effects
        ans += '\n' + declare + name + ' = ' + initial_value

        ans += comment_symbol + 'var initializer, id: ' + str(id(self))


        #ans = self.concat_side_effects(compiler_params, ans, side_effects)
        return ans

#    def to_initializer_source(self, compiler_params, is_instance):
#        print('to_initializer_source', is_instance, self)
#        if is_instance == False:
#            raise ValueError
#            full_name = compiler_params.get_varname(self.name, self.name, self.dtype)
#            return self.var_initializer(compiler_params, full_name)
#        return ''

class VarParam(Var):
    """
    Variable parameter that can be set before calling the solver.
    """
    

    def to_source_impl(self, compiler_params):
        #self.debug(compiler_params)
        if compiler_params.mode in [MODE_VARNAME, MODE_INLINE, MODE_ALWAYS_INLINE]:
            ans = compiler_params.get_varname(self.name, self.name, self.dtype, True, rank=self.log_intermediates_rank, subset_rank=self.log_intermediates_subset_rank, loop_specified_name=self.loop_specified_name, do_log=self.do_log)
            self.to_source_varname = ans
            return ans
        elif compiler_params.mode == MODE_SIDE_EFFECTS:
            return ''
        elif compiler_params.mode == MODE_SAMPLE_PROBLEM:
            return self.var_initializer(compiler_params.deroot())
        else:
            raise ValueError('unhandled mode', compiler_params.mode)

class LoopVar(Expr):
    def __init__(self, name, a, b=None, step=1):
        super().__init__()
        if b is None:
            self.children = [str(name), ConstExpr(0), to_expr(a), to_expr(step)]
        else:
            self.children = [str(name), ConstExpr(a), to_expr(b), to_expr(step)]
        self.dtype = INT_TYPE

    (name, initial, final, step) = gen_attrs([str, to_expr, to_expr, to_expr])


    def var_name(self, compiler_params):
        return self.name

    def to_source_impl(self, compiler_params):
        if compiler_params.mode == MODE_SIDE_EFFECTS:
            return ''
        return Expr.to_source_impl(self, compiler_params)

    def to_source_expr(self, compiler_params, mid_str=None, mid_str_no_indent=None):
        if mid_str is None:
            return self.name
        else:
            compiler_params = compiler_params.deroot().as_mode(MODE_INLINE)

            return mid_str_no_indent

class ArgumentArray(AlwaysInlineExpr):
    def __init__(self, name=DEFAULT_ARGUMENT_ARRAY_NAME, dtype=VECTOR_TYPE, initializer=None, ndims=4):

        super().__init__()
        self.ndims = ndims
        self.children = [str(name)]
        self.dtype = dtype
        self.initializer = initializer


    

    (name,) = gen_attrs([str])

    def __getitem__(self, index):
        return GetItem(self, index)

    def size(self):
        return GetSize(self)

#    def to_source(self, compiler_params):
#        if compiler_params.mode == MODE_SAMPLE_PROBLEM:
#            raise ValueError
#        return AlwaysInlineExpr.to_source(self, compiler_params)
    def to_source_inline(self, compiler_params):
        if self.name != DEFAULT_ARGUMENT_ARRAY_NAME:
            if compiler_params.mode == MODE_SAMPLE_PROBLEM:
                if self.initializer is not None:
                    return_val = self.name + ' = ' + self.initializer.to_source(compiler_params.deroot())
                    return return_val
        return AlwaysInlineExpr.to_source_inline(self, compiler_params)

    def to_source_impl(self, compiler_params):
        if self.name not in [DEFAULT_ARGUMENT_ARRAY_NAME, OUTPUT_ARRAY]:
            compiler_params.instance_dtype[self.name] = self.dtype

        return self.name

class Tuple(AlwaysInlineExpr):
    """A tuple that can be used only for indexing currently."""
    def __init__(self, t):
        super().__init__()
        self.children = [to_expr(e) for e in t]
        self.dtype = self.children[0].dtype

    def to_source_impl(self, compiler_params):
        return ','.join(e.to_source(compiler_params) for e in self.children)

class GetItem(Expr):
    def __init__(self, array, index):
        super().__init__()
        self.children = [to_expr(array), to_expr(index)]
        self.dtype = REAL_TYPE


    (array, index) = gen_attrs([to_expr, to_expr])
    
    def __getitem__(self, index):
        return GetItem(self, index)

   

    def to_source_expr(self, compiler_params):
        
        (lbrace, rbrace) = ('[', ']')

        return self.array.to_source(compiler_params) + lbrace + self.index.to_source(compiler_params) + rbrace

    def to_source_impl(self, compiler_params):
        ans = Expr.to_source_impl(self, compiler_params)
        op = '+'
        
        return ans

class GetSize(Expr):
    def __init__(self, array):
        super().__init__()
        self.children = [to_expr(array)]
        self.dtype = INT_TYPE

    (array,) = gen_attrs([to_expr])

    def to_source_expr(self, compiler_params):
        return self.array.to_source(compiler_params) + '.size()'

class Func(Expr):
    def __init__(self, name, tf_name=None, skip_log=False):
        super().__init__()
        self.children = [str(name)]
        self.tf_name = tf_name
        self.skip_log = skip_log
        if skip_log:
            self.do_log = False

    (name,) = gen_attrs([to_expr])

    def __call__(self, *args):
        return Call(self.name, *args, tf_name=self.tf_name, skip_log=self.skip_log)

    def to_source_expr(self, compiler_params):
        raise ValueError('Func should be called before conversion to source')

class Call(Expr):
    def __init__(self, name, *args, tf_name=None, skip_log=False):
        super().__init__()
        self.children = [str(name)] + [to_expr(a) for a in args]
        self.dtype = REAL_TYPE
        self.tf_name = tf_name

        if skip_log:
            self.do_log = False


   

    (name,) = gen_attrs([to_expr])

    def to_source_impl(self, compiler_params):
        
        return Expr.to_source_impl(self, compiler_params)

    def to_source_expr(self, compiler_params):
        return_list = []
        for a in self.children[1:]:
            return_list.append(a.to_source(compiler_params))

        func_name = self.tf_name
        return func_name + '(' + ','.join(return_list) + ')'

class TextureMap(Expr):
    def __init__(self, map_id, xx, yy):
        super().__init__()
        self.children = [int(map_id), to_expr(xx), to_expr(yy)]
        self.dtype = REAL_TYPE
        self.map_id = int(map_id)
        self.xx = xx
        self.yy = yy

    def to_source_expr(self, compiler_params):
        return 'tf.gather_nd(texture_maps[%d], tf.stack((tf.floormod(tf.cast(%s, tf.int32), tf.shape(texture_maps[%d])[0]), tf.floormod(tf.cast(%s, tf.int32), tf.shape(texture_maps[%d])[1])), 3))' % (self.map_id, self.children[1].to_source(compiler_params), self.map_id, self.children[2].to_source(compiler_params), self.map_id)

class TextureMapScaled(Expr):
    def __init__(self, map_id, xx, yy):
        super().__init__()
        self.children = [int(map_id), to_expr(xx), to_expr(yy)]
        self.dtype = REAL_TYPE
        self.map_id = int(map_id)
        self.xx = xx
        self.yy = yy

    def to_source_expr(self, compiler_params):
        return 'tf.gather_nd(texture_maps[%d], tf.stack((tf.cast(%s, tf.int32), tf.cast(%s, tf.int32)), 3))' % (self.map_id, self.children[1].to_source(compiler_params), self.children[2].to_source(compiler_params))
            
class TextureVarScaled(Expr):
    def __init__(self, texture_var, xx, yy):
        super().__init__()
        self.children = [to_expr(texture_var), to_expr(xx), to_expr(yy)]
        self.dtype = REAL_TYPE
        self.texture = texture_var
        self.xx = xx
        self.yy = yy
        
    def to_source_expr(self, compiler_params):
        return 'tf.gather_nd(%s[0], tf.stack((tf.cast(%s, tf.int32), tf.cast(%s, tf.int32)), 3))' % (self.children[0].to_source(compiler_params), self.children[1].to_source(compiler_params), self.children[2].to_source(compiler_params))
            
class TextureMapLinearUV(Expr):
    def __init__(self, map_id, xx, yy):
        super().__init__()
        self.children = [int(map_id), to_expr(xx), to_expr(yy)]
        self.dtype = REAL_TYPE
        self.map_id = int(map_id)
        self.xx = xx
        self.yy = yy

    def to_source_expr(self, compiler_params):
        return 'texture_linear_uv(texture_maps[%d], %s, %s)' % (self.map_id, self.children[1].to_source(compiler_params), self.children[2].to_source(compiler_params))
            
class TextureVarLinearUV(Expr):
    def __init__(self, texture_var, xx, yy):
        super().__init__()
        self.children = [to_expr(texture_var), to_expr(xx), to_expr(yy)]
        self.dtype = REAL_TYPE
        self.texture = texture_var
        self.xx = xx
        self.yy = yy
        
    def to_source_expr(self, compiler_params):
        return 'texture_linear_uv(%s[0], %s, %s)' % (self.children[0].to_source(compiler_params), self.children[1].to_source(compiler_params), self.children[2].to_source(compiler_params))
            
class TextureMapInterp(Expr):
    def __init__(self, map_id, xx, yy, filter='liner', wrap='clamp'):
        super().__init__()
        self.children = [int(map_id), to_expr(xx), to_expr(yy)]
        self.dtype = REAL_TYPE
        self.map_id = int(map_id)
        self.xx = xx
        self.yy = yy
        self.filter = filter
        self.wrap = wrap
        
    def to_source_expr(self, compiler_params):
        return 'texture_interp(texture_maps[%d], %s, %s, filter=%s, clamp=%s)' % (self.map_id, self.children[1].to_source(compiler_params), self.children[2].to_source(compiler_params), self.filter, self.wrap)

def numerical_promote(a, b):
    if a == REAL_TYPE or b == REAL_TYPE:
        return REAL_TYPE
    else:
        return a

def is_any_constant(b_str):
    try:
        b_val = eval(b_str)
        return True
    except:
        return False

def is_all_constant(e):
    return all(isinstance(node, (ConstExpr, BinaryOp, UnaryOp)) for node in e.all_nodes_generator())

def is_constant(b_str, b_value):
    eps = 1e-15
    #print('is_constant:', repr((b_str, b_value))) #, abs(eval(b_str) - b_value) <= eps)
    try:
        b_val = eval(b_str)
        diff = b_val - b_value
    except:
        #print('=> False')
        return False

    ans = abs(b_val - b_value) <= eps
    #print('=> ' + str(ans))
    return ans

def constant_value(b_str):
    ans = eval(b_str)
#    if ans != ():
#        return ConstExpr(ans)
#    return None
    return to_expr(ans)

class BinaryOp(Expr):
    def __init__(self, op, a, b):
        super().__init__()
        self.children = [str(op), to_expr(a), to_expr(b)]
        self.dtype = numerical_promote(self.children[1].dtype, self.children[2].dtype)
        assert isinstance(self.a, Expr)
        assert isinstance(self.b, Expr)

        


    (op, a, b) = gen_attrs([str, to_expr, to_expr])

    def __str__(self):
        return super().__str__() + '(' + self.op + ')'


    def simplify_impl(self):
        #traceback.print_stack()
        #print(self.op, self.a, self.b)
        #pprint.pprint(self)
        cp = CompilerParams()
        a = self.a_str(cp)
        #print('calling b_str on:')
        #pprint.pprint(self)
        #print('b_str')
        b = self.b_str(cp)
        if self.op == '*':
            if is_constant(b, 1.0):
                return_val = self.a
                simplify_clean_up_loop_dict(return_val, self.a, [self, self.b], do_log = self.a.do_log or self.do_log)
                return return_val
            elif is_constant(a, 1.0):
                return_val = self.b
                simplify_clean_up_loop_dict(return_val, self.b, [self, self.a], do_log = self.b.do_log or self.do_log)
                return return_val
            elif is_constant(b, 0.0) or is_constant(a, 0.0):
                return_val = ConstExpr(0.0)
                simplify_clean_up_loop_dict(return_val, self, [self.a, self.b], do_log=False)
                return return_val

            def handle_mul_mul_const(a_expr, b_expr, a_str):
                if is_any_constant(a_str) and isinstance(b_expr, BinaryOp) and b_expr.op == '*':
                    b_a = b_expr.a_str(cp)
                    b_b = b_expr.b_str(cp)
                    if is_any_constant(b_a):
                        return_val = to_expr(constant_value(a_str).value * constant_value(b_a).value) * b_expr.b
                        simplify_clean_up_loop_dict(return_val, self, [a_expr, b_expr.a], do_log = b_expr.b.do_log or self.do_log)
                        return return_val
                    if is_any_constant(b_b):
                        return_val = to_expr(constant_value(a_str).value * constant_value(b_b).value) * b_expr.a
                        simplify_clean_up_loop_dict(return_val, self, [a_expr, b_expr.b], do_log = b_expr.a.do_log or self.do_log)
                        return return_val

            arg_list = [(self.a, self.b, a), (self.b, self.a, b)]
            if isinstance(self.b, Var) and self.b.reduce is None:
                arg_list.append((self.a, self.b.initial_value, a))
            if isinstance(self.a, Var) and self.a.reduce is None:
                arg_list.append((self.b, self.a.initial_value, b))
            for (a_expr, b_expr, a_str) in arg_list:
                v1 = handle_mul_mul_const(a_expr, b_expr, a_str)
                if v1 is not None:
                    return v1
        elif self.op == '/':
            if is_constant(b, 1.0):
                return_val = self.a
                simplify_clean_up_loop_dict(return_val, self.a, [self, self.b], do_log = self.a.do_log or self.do_log)
                return return_val
        elif self.op == '+':
            if is_constant(a, 0.0):
                return_val = self.b
                simplify_clean_up_loop_dict(return_val, self.b, [self, self.a], do_log = self.b.do_log or self.do_log)
                return return_val
            elif is_constant(b, 0.0):
                return_val = self.a
                simplify_clean_up_loop_dict(return_val, self.a, [self, self.b], do_log = self.a.do_log or self.do_log)
                return return_val
        elif self.op == '-':
            if is_constant(b, 0.0):
                return_val = self.a
                simplify_clean_up_loop_dict(return_val, self.a, [self, self.b], do_log = self.a.do_log or self.do_log)
                return return_val
        elif self.op == '**':
            if is_constant(b, 1.0):
                return_val = self.a
                simplify_clean_up_loop_dict(return_val, self.a, [self, self.b], do_log = self.a.do_log or self.do_log)
            if is_constant(a, 0.0):
#                print('simplifying **, b: %s'%b)
                if is_any_constant(b):
                    bval = constant_value(b).value
#                    print('  is constant b, bval = %r'%bval)
                    if bval > 0.0:
#                        print('returning zero')
                        return_val = to_expr(0.0)
                        simplify_clean_up_loop_dict(return_val, self, [self.a, self.b], do_log=False)
                        return return_val

            if is_constant(b, 0.5):
                ap_L = [self.a]
                if isinstance(self.a, Var):
                    ap_L.append(self.a.initial_value)
                for ap in ap_L:
                    if isinstance(ap, BinaryOp) and ap.op == '*' and ap.a.identical(ap.b):
                        return_val = ap.a
                        simplify_clean_up_loop_dict(return_val, ap.a, ap_L + [self.b], do_log = ap.a.do_log or self.do_log)
                        return return_val
                    if isinstance(ap, BinaryOp) and ap.op == '**' and is_constant(ap.b_str(cp), 2.0):
                        return_val = ap.a
                        simplify_clean_up_loop_dict(return_val, ap.a, ap_L + [self.b, ap.b], do_log = ap.a.do_log or self.do_log)
                        return return_val

        if not is_all_constant(self):
            return self

        self_str = self.to_source(cp.as_mode(MODE_ALWAYS_INLINE))
        try:
            ans = constant_value(self_str)
            if ans is not None:
                simplify_clean_up_loop_dict(ans, self, [self.a, self.b], do_log=False)
                return ans

        except:
            pass

        return self

    def optional_simplify(self, E_var, do_simplify):
        (E, var) = E_var
#        E.check_acyclic()
#        var.check_acyclic()
        if not do_simplify:
            return (E, var)
        return (simplify(E), simplify(var))

    

    def a_str(self, compiler_params):

        if not is_all_constant(self.a):
            return ''
        
        ans = self.a.to_source(compiler_params.as_mode(MODE_ALWAYS_INLINE))
#        compiler_params.cache_to_source[key] = ans
        return ans

    def b_str(self, compiler_params):
        if not is_all_constant(self.b):
            return ''

        
        ans = self.b.to_source(compiler_params.as_mode(MODE_ALWAYS_INLINE))

        return ans

    def is_power(self, compiler_params, b_const, b=None):
        if b is None:
            b = self.b_str(compiler_params)
        
        if not self.op == '**':
            return False
        return is_constant(b, b_const)

    def integer_power(self, compiler_params, allow_float=False):
        """
        Gets int for power if it is an integer otherwise returns None.
        """
        if self.op != '**':
            return None
        b = self.b_str(compiler_params)
        try:
            b_val = eval(b)
        except:
            return None
        if allow_float and isinstance(b_val, int_types + float_types):
            return b_val
        if b_val == int(b_val):
            return int(b_val)
        return None

    def float_power(self, compiler_params):
        return self.integer_power(compiler_params, True)

    def pow_str(self, compiler_params, a, b):
        b_str = self.b_str(compiler_params)
        if self.is_power(compiler_params, -1.0, b_str):
            return '(1.0/(' + a + '))'
        if self.is_power(compiler_params, 0.0, b_str):
            return '(1.0)'
        if self.is_power(compiler_params, 1.0, b_str):
            return '(' + a + ')'
        if self.is_power(compiler_params, 2.0, b_str):
            return '((' + a + ') * (' + a + '))'
        if self.is_power(compiler_params, 3.0, b_str):
            return '((' + a + ') * (' + a + ') * (' + a + '))'
        if self.is_power(compiler_params, 0.5, b_str):
            return 'tf_np_wrapper("sqrt")(' + a + ')'
        if self.is_power(compiler_params, -0.5, b_str):
            return '(1.0 / tf_np_wrapper("sqrt")(' + a + '))'
        return 'pow(' + a + ', ' + b + ')'

    def to_source_expr(self, compiler_params):
        a = self.a.to_source(compiler_params)
        b = self.b.to_source(compiler_params)


        if self.op == '**':
            return self.pow_str(compiler_params, a, b)
        elif self.op == '%':
            return 'tf.floormod(' + a + ', ' + b + ')'
        else:
            return '((' + a + ')' + self.op + '(' + b + '))'


class Compound(Expr):
    """
    Combines several expressions into a compound expression.
    """
    def __init__(self, L):
        super().__init__()
        self.children = [to_expr(x) for x in L]
        if len(self.children):
            self.dtype = self.children[-1].dtype
        else:
            self.dtype = VOID_TYPE

    def to_source_impl(self, compiler_params):
        if compiler_params.mode == MODE_VARNAME:
            return '0.0'
        else:
            return_list = []
            for e in self.children:
                return_list.append(e.to_source(compiler_params))
            return '\n'.join(return_list)

class Assign(Expr):
    """
    Assigns lhs to rhs, with op optionally performing an in-place binary operation such as *= (op = '*'), += (op = '+'), etc.
    """
    def __init__(self, lhs, rhs, op=''):
        super().__init__()
        self.children = [to_expr(lhs), to_expr(rhs), str(op)]
        self.dtype = VOID_TYPE
        self.recurse_to_source_indices = slice(1, 2)

    (lhs, rhs, op) = gen_attrs([to_expr, to_expr, str])

    def to_source_expr(self, compiler_params):
        if compiler_params.chron_order:
            rhs_ans = self.rhs.to_source(compiler_params)
            return self.lhs.to_source(compiler_params.as_mode(MODE_ALWAYS_INLINE)) + ' ' + self.op + '= ' + rhs_ans
        else:
            return self.lhs.to_source(compiler_params.as_mode(MODE_ALWAYS_INLINE)) + ' ' + self.op + '= ' + self.rhs.to_source(compiler_params)


class UnaryOp(Expr):
    def __init__(self, op, a):
        super().__init__()
        self.children = [str(op), to_expr(a)]
        self.dtype = self.a.dtype

        

    (op, a) = gen_attrs([str, to_expr])

    def to_source_expr(self, compiler_params):
        return '(' + self.op + '(' + self.a.to_source(compiler_params) + '))'

    

def get_random_node(self):
    if hasattr(self, 'random'):
        return self.random
    self.random = random_uniform(0.0, 1.0)
    return self.random

def f_triangle_wave(x):
    T = 2.0
    xT_floor = floor(x/T)
    TxT_floor = T*floor(x/T)
    xf = x-T*xT_floor
    return min(xf, T-xf)

def get_gaussian_samples(arg_key, nsamples, ndims, cache={}):
    key = (arg_key, nsamples, ndims)
    if key in cache:
        return cache[key]
    N = numpy.random.normal(size=(nsamples, ndims))
    ans = N
    cache[key] = ans
    return ans




def clamp_var(var):
    min_var = 1e-20
    return max_nosmooth(var, min_var)

def printed(x):
    pprint.pprint(x)
    return x

np_perm = numpy.array([151, 160, 137, 91, 90, 15, 131, 13, 201, 95, 96, 53, 194, 233, 7, 225, 140, 36, 103, 30, 69, 142, 8, 99,
           37, 240, 21, 10, 23, 190, 6, 148, 247, 120, 234, 75, 0, 26, 197, 62, 94, 252, 219, 203, 117, 35, 11, 32,
           57, 177, 33, 88, 237, 149, 56, 87, 174, 20, 125, 136, 171, 168, 68, 175, 74, 165, 71, 134, 139, 48, 27,
           166, 77, 146, 158, 231, 83, 111, 229, 122, 60, 211, 133, 230, 220, 105, 92, 41, 55, 46, 245, 40, 244, 102,
           143, 54, 65, 25, 63, 161, 1, 216, 80, 73, 209, 76, 132, 187, 208, 89, 18, 169, 200, 196, 135, 130, 116,
           188, 159, 86, 164, 100, 109, 198, 173, 186, 3, 64, 52, 217, 226, 250, 124, 123, 5, 202, 38, 147, 118, 126,
           255, 82, 85, 212, 207, 206, 59, 227, 47, 16, 58, 17, 182, 189, 28, 42, 223, 183, 170, 213, 119, 248, 152,
           2, 44, 154, 163, 70, 221, 153, 101, 155, 167, 43, 172, 9, 129, 22, 39, 253, 19, 98, 108, 110, 79, 113, 224,
           232, 178, 185, 112, 104, 218, 246, 97, 228, 251, 34, 242, 193, 238, 210, 144, 12, 191, 179, 162, 241, 81,
           51, 145, 235, 249, 14, 239, 107, 49, 192, 214, 31, 181, 199, 106, 157, 184, 84, 204, 176, 115, 121, 50,
           45, 127, 4, 150, 254, 138, 236, 205, 93, 222, 114, 67, 29, 24, 72, 243, 141, 128, 195, 78, 66, 215, 61,
           156, 180])
np_perm2 = np_perm ** 2.0

np_grad3_0 = numpy.array([ 1., -1.,  1., -1.,  1., -1.,  1., -1.,  0.,  0.,  0.,  0.])
np_grad3_1 = numpy.array([1.,  1., -1., -1.,  0.,  0.,  0.,  0.,  1., -1.,  1., -1.])
np_grad3_2 = numpy.array([0.,  0.,  0.,  0.,  1.,  1., -1., -1.,  1.,  1., -1., -1.])


sign = Func('our_sign',                     # Ordinarily defined sign function, with sign(0) = 0
             tf_name = 'tf_np_wrapper("sign")')

sign_down = Func('our_sign_down',           # Sign function with sign(0) => -1
            tf_name = 'tf_np_wrapper("sign_down")')

sign_up   = Func('our_sign_up',             # Sign function with sign(0) => +1
            tf_name = 'tf_np_wrapper("sign_up")')

#def sign(a):
#    return erf(5.0 * a)

# A select() that is never smoothed: semantics are the same as an if statement (differing from Heaviside step)
select_nosmooth = Func('our_select',
            tf_name = 'select_nosmooth')

min = Func('min',
           tf_name='tf_np_wrapper("minimum")')
max = Func('max',
           tf_name='tf_np_wrapper("maximum")')
equal = Func('equal',
             tf_name='tf_np_wrapper("equal")')
nequal = Func('nequal',
             tf_name='tf_np_wrapper("nequal")')

select = select_nosmooth

ge0 = lambda x: sign_up(x)*0.5+0.5
gt0 = lambda x: sign_down(x)*0.5+0.5


random_uniform = Func('random_uniform',
                     tf_name = 'tf.random_uniform')

erf = Func('erf',
            tf_name = 'tf_np_wrapper("erf")')

exp = Func('exp',
            tf_name = 'tf_np_wrapper("exp")')

cos = Func('cos',
            tf_name = 'tf_np_wrapper("cos")')

sin = Func('sin',
            tf_name = 'tf_np_wrapper("sin")')

atan = Func('atan',
            tf_name = 'tf_np_wrapper("atan")')

# incorrect derivation
atan2_direct = Func('atan2_direct',
                     tf_name='tf_np_wrapper("atan2")')

# incorrect derivative
asin = Func('asin',
            tf_name='tf_np_wrapper("asin")')

def acos_deriv(x):
    return - (1 - x ** 2) ** -0.5

acos = Func('acos',
            tf_name = 'tf_np_wrapper("acos")')

floor = Func('floor',
            tf_name = 'tf_np_wrapper("floor")')

floor_from_fract = lambda x: (x - fract(x))

ceil = Func('ceil',
            tf_name = 'tf_np_wrapper("ceil")')

ceil_from_fract = lambda x: (x + fract(-x))

fract = Func('fract',
             tf_name = 'tf_fract')

fract_nosmooth = Func('fract',
             tf_name = 'tf_fract')

expand_1D = Func('expand_1D',
                 tf_name = 'tf_np_wrapper("expand_1D")',
                 skip_log = True)



lookup_table_np_perm = Func('lookup_table_np_perm',
                       tf_name = 'tf_lookup_table_np_perm')


lookup_table_np_grad0 = Func('lookup_table_np_grad0',
                        tf_name = 'tf_lookup_table_np_grad0')



lookup_table_np_grad1 = Func('lookup_table_np_grad1',
                        tf_name = 'tf_lookup_table_np_grad1')



lookup_table_np_grad2 = Func('lookup_table_np_grad2',
                        tf_name = 'tf_lookup_table_np_grad2')



simplex_noise = Func('simplex_noise',
                      tf_name='simplex_noise_2arg')

gabor_noise = Func('gabor_noise',
                   tf_name='simplex_noise')

sqrt = lambda arg: arg**0.5 #Func('sqrt', lambda x: ('0.5/sqrt(' + x[0] + ')',))
log = Func('log',
            tf_name = 'tf_np_wrapper("log")')

# Like min(), but never smoothed
min_nosmooth = Func('min',
            tf_name = 'tf_np_wrapper("minimum")')

# Like max(), but never smoothed
max_nosmooth = Func('max',
            tf_name = 'tf_np_wrapper("maximum")')

def loop_generator(n, name=None, cond=None, is_raymarching=False):
    if name is None:
        global loop_name_count
        name = loop_name_prefix + str(loop_name_count)
        loop_name_count += 1
        if is_raymarching:
            name = raymarching_loop_name_prefix + name
        else:
            global has_non_raymarching_loop
            has_non_raymarching_loop = True
    global DEFAULT_FOR_LOOP_NAME
    global DEFAULT_FOR_LOOP_ITER
    global DEFAULT_FOR_LOOP_COND
    default_for_loop_name = DEFAULT_FOR_LOOP_NAME
    default_for_loop_iter = DEFAULT_FOR_LOOP_ITER

    global DEFAULT_COND_FUNC
    if cond is not None:
        DEFAULT_COND_FUNC = cond

    DEFAULT_FOR_LOOP_NAME = name
    for i in range(n):
        DEFAULT_FOR_LOOP_ITER = i
        yield i

    DEFAULT_FOR_LOOP_NAME = default_for_loop_name
    DEFAULT_FOR_LOOP_ITER = default_for_loop_iter
    DEFAULT_COND_FUNC = None
    
class def_generator:
    def __init__(self, func):
        self.iter_count = 0
        global def_func_names
        
        if func.__name__ not in def_func_names:
            self.name = def_name_prefix + func.__name__
            def_func_names[func.__name__] = 1
        else:
            self.name = def_name_prefix + func.__name__ + '%03d' % def_func_names[func.__name__]
            def_func_names[func.__name__] += 1
            
        self.func = func
        
    def __call__(self, *args):
        
        new_args = []
        
        if 'texcube' in self.name:
            print('here')
                
        for arg in args:
            if isinstance(arg, Expr):
                arg = arg * 1.0
                
            if isinstance(arg, (numpy.ndarray, list)):
                for i in range(len(arg)):
                    if isinstance(arg[i], Expr):
                        arg[i] = arg[i] * 1.0
            new_args.append(arg)
                
        args = tuple(new_args)
    
        global DEFAULT_FOR_LOOP_NAME
        global DEFAULT_FOR_LOOP_ITER
        default_for_loop_name = DEFAULT_FOR_LOOP_NAME
        default_for_loop_iter = DEFAULT_FOR_LOOP_ITER
        
        DEFAULT_FOR_LOOP_NAME = self.name
        DEFAULT_FOR_LOOP_ITER = self.iter_count
        ans = self.func(*args)
        
        DEFAULT_FOR_LOOP_NAME = default_for_loop_name
        DEFAULT_FOR_LOOP_ITER = default_for_loop_iter
        self.iter_count += 1
        
        return ans
        
